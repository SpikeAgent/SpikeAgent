{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0682f6f5",
   "metadata": {},
   "source": [
    "# VLM Spike Curation Tutorial\n",
    "\n",
    "This tutorial will guide you through using AI (Vision Language Models) to help curate spike sorting results by automatically identifying which units should be merged together.\n",
    "\n",
    "## What is Spike Curation?\n",
    "\n",
    "After spike sorting, you often have multiple units that actually represent the same neuron. **Curation** is the process of identifying and merging these duplicate units to get a cleaner, more accurate representation of your neural data.\n",
    "\n",
    "## What This Tutorial Does\n",
    "\n",
    "This tutorial uses AI to:\n",
    "1. **Find potential merge candidates** - Automatically identifies units that might be duplicates\n",
    "2. **Analyze visual features** - Uses AI to examine crosscorrelograms and amplitude plots\n",
    "3. **Make merge decisions** - The AI decides which units should be merged based on visual analysis\n",
    "4. **Save results** - Creates a log of all merge decisions for review\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "- A spikeinterface SortingAnalyzer object (from a completed spike sorting run)\n",
    "- An OpenAI API key (for GPT-4o) or other supported model\n",
    "- The required Python packages installed\n",
    "\n",
    "Let's get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "756e9d01",
   "metadata": {},
   "source": [
    "# ## Step 0: Set Up Your API Keys\n",
    "# \n",
    "# **IMPORTANT:** Before starting this tutorial, you must configure your API keys. These keys allow the AI models to process and analyze your spike sorting data. Based on our experience, GPT-4o is the fastest model for spike curation tasks.\n",
    "# \n",
    "# ### Which API Key Do You Need?\n",
    "# \n",
    "# - **Recommended (GPT-4o):** Set your `OPENAI_API_KEY`\n",
    "# \n",
    "# ### How to Obtain Your API Keys\n",
    "# \n",
    "# - **OpenAI:** https://platform.openai.com/api-keys\n",
    "# - **Anthropic:** https://console.anthropic.com/\n",
    "# - **Google:** https://makersuite.google.com/app/apikey\n",
    "# \n",
    "# ### Configuring Your `.env` File\n",
    "# \n",
    "# Run the cell below to create or update your `.env` file with your API keys. This file will be automatically loaded by the tutorial.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ddd795",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Create or update .env file with your API keys\n",
    "# Replace the values below with your actual API keys\n",
    "\n",
    "env_content = \"\"\"# API Keys for Spike Agent\n",
    "# Replace the values below with your actual API keys\n",
    "# You can leave keys empty if you're not using that provider\n",
    "\n",
    "# OpenAI API Key (required for GPT-4o, GPT-4o-mini, etc.)\n",
    "OPENAI_API_KEY=your_openai_key_here\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Write .env file\n",
    "with open('.env', 'w') as f:\n",
    "    f.write(env_content)\n",
    "\n",
    "print(\".env file created!\")\n",
    "print(\"\\n   IMPORTANT: Please edit the .env file and replace:\")\n",
    "print(\"   - 'your_openai_key_here' with your actual OpenAI API key\")\n",
    "print(\"\\n  You can edit the .env file in your file explorer or text editor.\")\n",
    "print(\"   Make sure there are NO spaces around the = sign!\")\n",
    "print(\"\\nAfter updating the .env file, run the next cell to verify your keys are loaded.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50725b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Only check for OpenAI (GPT-4o) API key\n",
    "print(\"Checking for OpenAI GPT-4o API key...\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "openai_key = os.getenv(\"OPENAI_API_KEY\", \"\")\n",
    "\n",
    "if openai_key and openai_key != \"your_openai_key_here\":\n",
    "    print(\"OPENAI_API_KEY: Found (ready to use GPT-4o)\")\n",
    "    print(\"-\" * 50)\n",
    "    print(\"\\nGreat! GPT-4o is ready to use.\")\n",
    "    print(\"   You can proceed with the tutorial.\")\n",
    "    print(\"\\nAvailable model:\")\n",
    "    print(\"   - GPT-4o\")\n",
    "else:\n",
    "    print(\"OPENAI_API_KEY: Not found or not updated\")\n",
    "    print(\"-\" * 50)\n",
    "    print(\"\\nERROR: OpenAI API key not found!\")\n",
    "    print(\"   Please edit the .env file and add your OpenAI API key.\")\n",
    "    print(\"   Then re-run this cell to verify.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b5072f1",
   "metadata": {},
   "source": [
    "**Once you've verified your API keys are loaded above, you can proceed to the next steps!**\n",
    "\n",
    "The tutorial will use these keys automatically when you call `get_model()`. Make sure you have at least one key set up before continuing.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c89a843",
   "metadata": {},
   "source": [
    "## Step 1: Import Required Libraries\n",
    "\n",
    "First, we need to import the necessary libraries. We'll use:\n",
    "- **spikeinterface** - For loading and working with spike sorting data\n",
    "- **matplotlib** - For plotting and visualization\n",
    "- **PIL** - For image processing\n",
    "- Custom tools from this package for VLM merge analysis\n",
    "\n",
    "The `si.set_global_job_kwargs(n_jobs=-1)` sets spikeinterface to use all available CPU cores for faster processing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "295edec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import spikeinterface.full as si\n",
    "si.set_global_job_kwargs(n_jobs=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a33d509a",
   "metadata": {},
   "source": [
    "## Step 2: Load Your Sorting Analyzer\n",
    "\n",
    "**Important:** Replace `<path_to_analyzer_folder>` with the actual path to your SortingAnalyzer folder.\n",
    "\n",
    "The SortingAnalyzer contains all the information about your spike sorting results, including:\n",
    "- Spike times for each unit\n",
    "- Waveforms\n",
    "- Quality metrics\n",
    "- Template information\n",
    "\n",
    "**Example path:** `\"/path/to/your/sorting_analyzer_folder\"`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "273b5e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorting_folder = \"<path_to_analyzer_folder>\"\n",
    "analyzer_to_merge = si.load_sorting_analyzer(sorting_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ff6c24b",
   "metadata": {},
   "source": [
    "## Step 3: Find Potential Merge Candidates\n",
    "\n",
    "This step automatically identifies units that might be duplicates and should be merged.\n",
    "\n",
    "### How It Works\n",
    "\n",
    "The algorithm uses **template similarity** to find units with similar waveforms. Units with very similar templates (above 90% similarity by default) are grouped together as potential merge candidates.\n",
    "\n",
    "### Parameters Explained\n",
    "\n",
    "- **`template_diff_thresh: 0.9`** - Units must be at least 90% similar to be considered for merging\n",
    "  - Lower values (e.g., 0.8) = more aggressive merging (more units grouped)\n",
    "  - Higher values (e.g., 0.95) = more conservative (fewer units grouped)\n",
    "\n",
    "- **`resolve_graph=False`** - We're just finding candidates, not merging yet\n",
    "\n",
    "### Output\n",
    "\n",
    "The code will print how many potential merge groups were found and show the first 15 groups. Each group is a list of unit IDs that might represent the same neuron.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65eb8507",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spikeinterface.curation import compute_merge_unit_groups\n",
    "print(\"--- Step 1: Computing potential merge candidates ---\")\n",
    "steps = [\"template_similarity\"]\n",
    "steps_params = {\n",
    "    \"template_similarity\": {\"template_diff_thresh\": 0.9}\n",
    "}\n",
    "potential_merge_groups = compute_merge_unit_groups(\n",
    "    analyzer_to_merge,\n",
    "    resolve_graph=False,\n",
    "    steps_params=steps_params,\n",
    "    steps=steps\n",
    ")\n",
    "\n",
    "num_groups = len(potential_merge_groups)\n",
    "print(f\"Found {num_groups} potential merge groups.\")\n",
    "if num_groups > 15:\n",
    "    print(\"Showing only the first 15 groups:\")\n",
    "for i, group in enumerate(potential_merge_groups[:15]):\n",
    "    print(f\"  Group {i}: {group}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9fc4d92",
   "metadata": {},
   "source": [
    "## Step 4: Helper Functions for Image Processing\n",
    "\n",
    "These functions help prepare images for the AI to analyze:\n",
    "\n",
    "- **`concat_images_horizontally()`** - Combines multiple images side-by-side so the AI can compare them\n",
    "- **`plot_concat_images()`** - Displays the combined images\n",
    "\n",
    "These are utility functions used internally by the VLM merge process. You don't need to modify them, but they're here if you want to visualize the images yourself.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f348a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import io\n",
    "import base64\n",
    "import pandas as pd\n",
    "\n",
    "def concat_images_horizontally(b64_images, resize_height=300):\n",
    "    images = [Image.open(io.BytesIO(base64.b64decode(b64))) for b64 in b64_images]\n",
    "\n",
    "    if resize_height is not None:\n",
    "        images = [\n",
    "            img.resize((int(img.width * resize_height / img.height), resize_height))\n",
    "            for img in images\n",
    "        ]\n",
    "    \n",
    "    total_width = sum(img.width for img in images)\n",
    "    max_height = max(img.height for img in images)\n",
    "    \n",
    "    new_img = Image.new(\"RGB\", (total_width, max_height), (255, 255, 255))\n",
    "    \n",
    "    x_offset = 0\n",
    "    for img in images:\n",
    "        new_img.paste(img, (x_offset, 0))\n",
    "        x_offset += img.width\n",
    "    \n",
    "    return new_img\n",
    "\n",
    "def plot_concat_images(b64_images):\n",
    "    img = concat_images_horizontally(b64_images)\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(15, 4))\n",
    "    ax.imshow(img)\n",
    "    ax.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87b7144b",
   "metadata": {},
   "source": [
    "## Step 5: Prepare for VLM Analysis\n",
    "\n",
    "This step sets up the AI model and prepares the images for analysis.\n",
    "\n",
    "### What Happens Here\n",
    "\n",
    "1. **Model Selection** - Choose any supported vision model (OpenAI, Anthropic, or Google)\n",
    "2. **API Key Verification** - Automatically checks that you have the correct API key for your chosen model\n",
    "3. **Folder Setup** - Determines where to save merge images and results\n",
    "4. **Image Generation** - Creates visualization images for each potential merge group\n",
    "\n",
    "### Available Models\n",
    "\n",
    "You can use any of these models by changing the `model_name` variable:\n",
    "\n",
    "**OpenAI Models:**\n",
    "- `\"gpt-4o\"` (recommended, best vision capabilities)\n",
    "- `\"gpt-4o-mini\"` (faster, cheaper)\n",
    "- `\"gpt-4-turbo\"`\n",
    "- `\"gpt-3.5-turbo\"`\n",
    "\n",
    "**Anthropic Models:**\n",
    "- `\"claude_4_sonnet\"`\n",
    "- `\"claude_3_5_sonnet\"`\n",
    "- `\"claude_3_opus\"`\n",
    "- `\"claude_3_haiku\"` (fastest)\n",
    "\n",
    "**Google Models:**\n",
    "- `\"gemini-2.5-pro\"`\n",
    "- `\"gemini-1.5-flash\"` (fastest)\n",
    "- `\"gemini-1.5-pro\"`\n",
    "\n",
    "### Important Notes\n",
    "\n",
    "- **Model Selection**: Change `model_name = \"gpt-4o\"` to any model from the list above\n",
    "- **API Key**: The code automatically checks for the correct API key based on your model choice\n",
    "- **Sorting Folder**: The code automatically finds your sorting folder, but you can set it manually if needed\n",
    "- **Image Creation**: This may take a few minutes depending on how many merge candidates you have\n",
    "\n",
    "The `merge_img_df` contains all the images that will be sent to the AI for analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e2601eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Part 2: Run VLM Merge Decision ---\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Ensure .env file is loaded (in case notebook was restarted)\n",
    "load_dotenv()\n",
    "\n",
    "import tool.si_custom as sic\n",
    "from tool.vlm_merge import run_vlm_merge, plot_merge_results\n",
    "from tool.utils import get_model\n",
    "from spikeinterface.curation.curation_tools import resolve_merging_graph\n",
    "\n",
    "if len(potential_merge_groups) == 0:\n",
    "    print(\"NO_MERGE_CANDIDATES::No potential merge groups found. Skipping VLM merge analysis.\")\n",
    "    # Set the output to be the same as the input if no merges are performed\n",
    "    merged_analyzer = analyzer_to_merge\n",
    "else:\n",
    "    print(\"\\n--- Step 2: Running VLM to decide on merges ---\")\n",
    "    \n",
    "    # Choose which model to use (you can change this to any supported model)\n",
    "    # Available models:\n",
    "    # OpenAI: \"gpt-4o\", \"gpt-4o-mini\", \"gpt-4-turbo\", \"gpt-3.5-turbo\"\n",
    "    # Anthropic: \"claude_4_sonnet\", \"claude_3_5_sonnet\", \"claude_3_opus\", \"claude_3_haiku\"\n",
    "    # Google: \"gemini-2.5-pro\", \"gemini-1.5-flash\", \"gemini-1.5-pro\"\n",
    "    model_name = \"gpt-4o\"  # Change this to your preferred model\n",
    "    \n",
    "    # Verify API key is available for the selected model\n",
    "    openai_key = os.getenv(\"OPENAI_API_KEY\", \"\")\n",
    "    anthropic_key = os.getenv(\"ANTHROPIC_API_KEY\", \"\")\n",
    "    google_key = os.getenv(\"GOOGLE_API_KEY\", \"\")\n",
    "    \n",
    "    # Check which provider the model belongs to\n",
    "    openai_models = [\"gpt-4o\", \"gpt-4o-mini\", \"gpt-4.1\", \"o1\", \"gpt-4-turbo\", \"gpt-3.5-turbo\"]\n",
    "    anthropic_models = [\"claude_4_sonnet\", \"claude_4_opus\", \"claude_3_7_sonnet\", \"claude_3_5_sonnet\", \"claude_3_opus\", \"claude_3_haiku\", \"claude_3_sonnet\"]\n",
    "    google_models = [\"gemini-2.5-pro\", \"gemini-2.0-flash-exp\", \"gemini-1.5-flash\", \"gemini-1.5-flash-8b\", \"gemini-1.5-pro\"]\n",
    "    \n",
    "    if model_name in openai_models:\n",
    "        if not openai_key or openai_key == \"your_openai_key_here\":\n",
    "            raise ValueError(\n",
    "                f\"ERROR: OPENAI_API_KEY not found for model '{model_name}'!\\n\"\n",
    "                \"Please go back to Step 0 and set up your OpenAI API key in the .env file.\\n\"\n",
    "                \"The .env file should contain: OPENAI_API_KEY=your_actual_key_here\"\n",
    "            )\n",
    "    elif model_name in anthropic_models:\n",
    "        if not anthropic_key or anthropic_key == \"your_anthropic_key_here\":\n",
    "            raise ValueError(\n",
    "                f\"ERROR: ANTHROPIC_API_KEY not found for model '{model_name}'!\\n\"\n",
    "                \"Please go back to Step 0 and set up your Anthropic API key in the .env file.\\n\"\n",
    "                \"The .env file should contain: ANTHROPIC_API_KEY=your_actual_key_here\"\n",
    "            )\n",
    "    elif model_name in google_models:\n",
    "        if not google_key or google_key == \"your_google_key_here\":\n",
    "            raise ValueError(\n",
    "                f\"ERROR: GOOGLE_API_KEY not found for model '{model_name}'!\\n\"\n",
    "                \"Please go back to Step 0 and set up your Google API key in the .env file.\\n\"\n",
    "                \"The .env file should contain: GOOGLE_API_KEY=your_actual_key_here\"\n",
    "            )\n",
    "    else:\n",
    "        raise ValueError(f\"ERROR: Unknown model '{model_name}'. Please check the model name.\")\n",
    "    \n",
    "    print(f\"API key loaded. Initializing model: {model_name}...\")\n",
    "    model = get_model(model_name=model_name)\n",
    "    # The `sorting_folder` should be defined from a previous step, but we fall back gracefully.\n",
    "    print(f\"sorting_folder: {sorting_folder}\") # The agent should check if the sorting_folder is defined first before falling back to current directory\n",
    "    if 'sorting_folder' not in globals() or sorting_folder is None:\n",
    "        if analyzer_to_merge.folder:\n",
    "            sorting_folder = os.path.dirname(analyzer_to_merge.folder)\n",
    "        else:\n",
    "            sorting_folder = os.getcwd() # Fallback to current directory\n",
    "            print(f\"Warning: `sorting_folder` not found. Defaulting to current directory: {sorting_folder}\")\n",
    "\n",
    "    merge_img_df = sic.create_merge_img_df(analyzer_to_merge, unit_groups=potential_merge_groups, load_if_exists=False, save_folder=sorting_folder)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e5cc38c",
   "metadata": {},
   "source": [
    "## Step 6: Run AI Merge Analysis\n",
    "\n",
    "This is the main step where the AI analyzes each potential merge group and decides whether units should be merged.\n",
    "\n",
    "### How the AI Makes Decisions\n",
    "\n",
    "The AI looks at two types of visual features:\n",
    "\n",
    "1. **Crosscorrelograms** - Shows the temporal relationship between spikes from different units\n",
    "   - If units are the same neuron, their crosscorrelogram should show a sharp peak at time 0\n",
    "   - If units are different neurons, the crosscorrelogram should be flat\n",
    "\n",
    "2. **Amplitude Plots** - Shows the distribution of spike amplitudes over time\n",
    "   - Same neuron = similar amplitude distributions\n",
    "   - Different neurons = different amplitude patterns\n",
    "\n",
    "### Parameters Explained\n",
    "\n",
    "- **`features`** - Which visual features to analyze\n",
    "  - `[\"crosscorrelograms\", \"amplitude_plot\"]` - Analyze both\n",
    "  - `[\"crosscorrelograms\"]` - Only crosscorrelograms (faster)\n",
    "  - `[\"amplitude_plot\"]` - Only amplitude plots\n",
    "\n",
    "- **`good_merge_groups=[1]`** - Example groups that are known good merges (for training/calibration)\n",
    "- **`bad_merge_groups=[0]`** - Example groups that are known bad merges (for training/calibration)\n",
    "- **`num_workers=50`** - Number of parallel workers (adjust based on your system)\n",
    "\n",
    "### Output\n",
    "\n",
    "The function returns a DataFrame with:\n",
    "- Merge group IDs\n",
    "- AI's decision (merge or don't merge)\n",
    "- Reasoning/explanation for each decision\n",
    "- Confidence scores\n",
    "\n",
    "The results are automatically saved to `vlm_merge_reasoning.csv` in your sorting folder for review.\n",
    "\n",
    "### What to Expect\n",
    "\n",
    "- **Processing Time**: This can take 10-30 minutes depending on the number of merge candidates\n",
    "- **API Costs**: Each merge group requires an API call. Monitor your usage if using paid APIs\n",
    "- **Results**: Review the CSV file to see the AI's reasoning before applying merges\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c6b4c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_results_df = run_vlm_merge(\n",
    "    model=model,\n",
    "    merge_unit_groups=potential_merge_groups,\n",
    "    img_df=merge_img_df,\n",
    "    features=[\"crosscorrelograms\", \"amplitude_plot\"], # available options are: [\"crosscorrelograms\", \"amplitude_plot\"]\n",
    "    good_merge_groups=[1], \n",
    "    bad_merge_groups=[0],\n",
    "    num_workers=50\n",
    ")\n",
    "\n",
    "# Save CSV to deterministic path derived from analyzer\n",
    "print(f\"Using sorting_folder for merge outputs: {sorting_folder}\")\n",
    "merge_csv_path = os.path.join(sorting_folder,'vlm_merge_reasoning.csv')\n",
    "merge_results_df.to_csv(merge_csv_path)\n",
    "print(f\"VLM merge reasoning log saved to: {merge_csv_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24e51394",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "After running the analysis, you should:\n",
    "\n",
    "1. **Review the Results** - Open `vlm_merge_reasoning.csv` and check the AI's decisions\n",
    "2. **Verify Merge Decisions** - Look at a few examples manually to ensure the AI is making good decisions\n",
    "3. **Apply Merges** - If you're satisfied, you can apply the merges using spikeinterface's merge functions\n",
    "4. **Re-analyze** - After merging, you may want to re-run quality metrics and create a new SortingAnalyzer\n",
    "\n",
    "## Tips for Best Results\n",
    "\n",
    "- **Start with conservative thresholds** (0.9-0.95) to avoid false positives\n",
    "- **Review a sample** of merge decisions before applying all of them\n",
    "- **Adjust parameters** based on your data quality and needs\n",
    "- **Use good/bad examples** if you have known merge cases to improve AI accuracy\n",
    "\n",
    "## Troubleshooting\n",
    "\n",
    "- **No merge candidates found**: Try lowering `template_diff_thresh` or check your data quality\n",
    "- **AI making poor decisions**: Provide more good/bad examples or adjust the features being analyzed\n",
    "- **Slow processing**: Reduce `num_workers` or analyze fewer features at once\n",
    "- **API errors**: Check your API key and rate limits\n",
    "\n",
    "Good luck with your curation!\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jongmin",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
